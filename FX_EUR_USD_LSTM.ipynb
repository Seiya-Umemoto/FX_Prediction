{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import oandapyV20\n",
    "import configparser\n",
    "import datetime\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accountID = \"\"\n",
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "V20Error",
     "evalue": "{\"errorMessage\":\"Insufficient authorization to perform request.\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mV20Error\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8db32bc374b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2019-01-01 00:00:00'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[0minstrument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'EUR_USD'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_period_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstrument\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minstrument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-8db32bc374b4>\u001b[0m in \u001b[0;36mget_period_data\u001b[1;34m(start, end, minute, instrument)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msend_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstrument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mconcats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#         print(df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-8db32bc374b4>\u001b[0m in \u001b[0;36msend_api\u001b[1;34m(count, start, minute, instrument)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'from'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstruments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInstrumentsCandles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstrument\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minstrument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# レスポンスの整形\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\oandapyV20\\oandapyV20.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, endpoint)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             response = self.__request(method, url,\n\u001b[1;32m--> 306\u001b[1;33m                                       request_args, headers=headers)\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\oandapyV20\\oandapyV20.py\u001b[0m in \u001b[0;36m__request\u001b[1;34m(self, method, url, request_args, headers, stream)\u001b[0m\n\u001b[0;32m    241\u001b[0m                          response.content.decode('utf-8'))\n\u001b[0;32m    242\u001b[0m             raise V20Error(response.status_code,\n\u001b[1;32m--> 243\u001b[1;33m                            response.content.decode('utf-8'))\n\u001b[0m\u001b[0;32m    244\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mV20Error\u001b[0m: {\"errorMessage\":\"Insufficient authorization to perform request.\"}"
     ]
    }
   ],
   "source": [
    "from oandapyV20 import API\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "# start～endまでのデータ取得\n",
    "def get_period_data(start, end, minute, instrument):\n",
    "    timestamp = start.timestamp()\n",
    "    concats = []\n",
    "    count = 5000\n",
    "    while True:\n",
    "        df, last_timestamp = send_api(count, timestamp, minute, instrument)\n",
    "        concats.append(df)\n",
    "#         print(df)\n",
    "        if last_timestamp > end.timestamp() or len(df) < count:\n",
    "            break\n",
    "        timestamp = last_timestamp + (60 * minute)\n",
    "    df = pd.concat(concats)\n",
    "    if end is None:\n",
    "        print(df)\n",
    "        return df\n",
    "    else:\n",
    "        return df[df.index < end]\n",
    "# 時間足のdfを取得\n",
    "def send_api(count, start, minute, instrument):\n",
    "    # oandaへのリクエストの送信\n",
    "    #api_key = '取得したアクセストークンを入れてください'\n",
    "    api = API(access_token=api_key, environment=\"practice\", headers={\"Accept-Datetime-Format\":\"Unix\"})\n",
    "    if minute == 1/60:\n",
    "        granularity = 'S5'\n",
    "    elif minute == 1:\n",
    "        granularity = 'M1'\n",
    "    elif minute == 5:\n",
    "        granularity = 'M5'\n",
    "    elif minute == 15:\n",
    "        granularity = 'M15'\n",
    "    elif minute == 60:\n",
    "        granularity = 'H1'\n",
    "    params = {\n",
    "        'count': count,\n",
    "        'granularity': granularity,\n",
    "    }\n",
    "    if start is not None:\n",
    "        params['from'] = start\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument, params=params)\n",
    "    response = api.request(r)\n",
    "\n",
    "    # レスポンスの整形\n",
    "    def join_json(candle):\n",
    "        tmp = candle['mid']\n",
    "        tmp['time'] = candle['time']\n",
    "        tmp['v'] = candle['volume']\n",
    "        tmp['complete'] = candle['complete']\n",
    "        return tmp\n",
    "    data_list = [join_json(candle) for candle in response['candles']]\n",
    "    df = pd.DataFrame(data_list)\n",
    "    last_timestamp = int(float(df.iloc[-1]['time']))\n",
    "    \n",
    "    # 型変更\n",
    "    df['time'] = df['time'].astype('float64')\n",
    "    df['o'] = df['o'].astype('float64')\n",
    "    df['h'] = df['h'].astype('float64')\n",
    "    df['l'] = df['l'].astype('float64')\n",
    "    df['c'] = df['c'].astype('float64')\n",
    "    df['v'] = df['v'].astype('float64')\n",
    "\n",
    "    # タイムゾーンの変更、インデックス化\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df['time'] = df['time'] + pd.Timedelta('09:00:00') # 日本時間へ変換\n",
    "    df.set_index('time', inplace=True)                 # 時間をインデックスにする\n",
    "    df = df.loc[:,['o','h','l', 'c', 'v', 'complete']] # 列の順番変更\n",
    "    df = df.rename(columns={'o': 'open', 'h': 'high', 'l': 'low', 'c': 'close', 'v': 'amount'})\n",
    "\n",
    "    return df, last_timestamp\n",
    "minute = 60\n",
    "start = datetime.strptime('2018-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "# end = datetime.now()\n",
    "end = datetime.strptime('2019-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "instrument = 'EUR_USD'\n",
    "df = get_period_data(start, end, minute, instrument=instrument)\n",
    "df = df.reset_index().drop_duplicates(subset='time',keep='first').set_index('time')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(columns=['complete']) #Mistake in naming the variable...:( it's not supposed to be df_open\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_new, test_size=0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm_in = []\n",
    "for i in range(len(train)-window_len):\n",
    "    temp = train[i:(i+window_len)].copy()\n",
    "    for col in train:\n",
    "        temp.loc[:, col] = temp[col] / temp[col].iloc[0] - 1\n",
    "    train_lstm_in.append(temp)\n",
    "lstm_train_out = (train['close'][window_len:].values / train['close'][:-window_len].values)-1\n",
    "\n",
    "test_lstm_in = []\n",
    "for i in range(len(test) - window_len):\n",
    "    temp = test[i:(i + window_len)].copy()\n",
    "    for col in test:\n",
    "        temp.loc[:, col] = temp[col] / temp[col].iloc[0] - 1\n",
    "    test_lstm_in.append(temp)\n",
    "lstm_test_out = (test['close'][window_len:].values / test['close'][:-window_len].values)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm_in = [np.array(train_lstm_input) for train_lstm_input in train_lstm_in]\n",
    "train_lstm_in = np.array(train_lstm_in)\n",
    "\n",
    "test_lstm_in = [np.array(test_lstm_input) for test_lstm_input in test_lstm_in]\n",
    "test_lstm_in = np.array(test_lstm_in)\n",
    "test_lstm_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs, output_size, neurons, activ_func=\"linear\",\n",
    "               dropout=0.25, loss=\"mae\", optimizer=\"adam\"):\n",
    "    model = Sequential()\n",
    "    \n",
    "    #(4944, 24, 5)\n",
    "    model.add(LSTM(neurons, return_sequences=True, input_shape = (inputs.shape[1], inputs.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(LSTM(neurons, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(LSTM(neurons, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(LSTM(neurons))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "    \n",
    "#     model.add(LSTM(neurons, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(Dense(units=output_size))\n",
    "#     model.add(Activation(activ_func))\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "np.random.seed(202)\n",
    "\n",
    "yen_model = build_model(train_lstm_in, output_size=1, neurons=50)\n",
    "\n",
    "yen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yen_history = yen_model.fit(train_lstm_in, lstm_train_out, epochs=100, batch_size=32, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1)\n",
    "\n",
    "ax1.plot(yen_history.epoch, yen_history.history['loss'])\n",
    "ax1.set_title('TrainingError')\n",
    "\n",
    "if yen_model.loss == 'mae':\n",
    "    ax1.set_ylabel('Mean Absolute Error (MAE)',fontsize=12)\n",
    "else:\n",
    "    ax1.set_ylabel('Model Loss',fontsize=12)\n",
    "ax1.set_xlabel('# Epochs',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools.eval_measures import rmse\n",
    "fig, ax1 = plt.subplots(1,1,figsize=(12,8))\n",
    "ax1.plot(train.index[window_len:],\n",
    "    train['close'][window_len:], label='Actual', color='blue', )\n",
    "ax1.legend()\n",
    "ax1.plot(train.index[window_len:],\n",
    "    ((np.transpose(yen_model.predict(train_lstm_in))+1)*train['close'].values[:-window_len])[0],\n",
    "            label='Predicted', color='red')\n",
    "ax1.legend()\n",
    "ax1.set_title('Prediction for Training Data({})'.format(instrument))\n",
    "ax1.grid(True)\n",
    "\n",
    "error_train = rmse(train['close'][window_len:], ((np.transpose(yen_model.predict(train_lstm_in))+1)*train['close'].values[:-window_len])[0])\n",
    "print('STD of train data[close]: {}'.format(train['close'].std()))\n",
    "print(f'RMSE: {error_train}')\n",
    "per = round(error_train/train['close'].std()*100, 2)\n",
    "print('Percentage RMSE/STD: {}%'.format(per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1,figsize=(12,8))\n",
    "ax1.plot(test.index[window_len:],\n",
    "    test['close'][window_len:], label='Actual', color='blue')\n",
    "ax1.legend()\n",
    "ax1.plot(test.index[window_len:],\n",
    "    ((np.transpose(yen_model.predict(test_lstm_in))+1)*test['close'].values[:-window_len])[0],\n",
    "            label='Predicted', color='red')\n",
    "ax1.legend()\n",
    "ax1.set_title('Prediction for Test Data({})'.format(instrument))\n",
    "ax1.grid(True)\n",
    "\n",
    "error_test = rmse(test['close'][window_len:], ((np.transpose(yen_model.predict(test_lstm_in))+1)*test['close'].values[:-window_len])[0])\n",
    "print('STD of test data[close]: {}'.format(test['close'].std()))\n",
    "print(f'RMSE: {error_test}')\n",
    "per = round(error_test/test['close'].std()*100, 2)\n",
    "print('Percentage RMSE/STD: {}%'.format(per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['close'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.columns[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yen_model.save(\"LSTM_FX_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model(\"LSTM_FX_Model\")\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
