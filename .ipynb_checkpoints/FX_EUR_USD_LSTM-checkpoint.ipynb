{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import oandapyV20\n",
    "import configparser\n",
    "import datetime\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accountID = \"\"\n",
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>amount</th>\n",
       "      <th>complete</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2018-01-02 07:00:00</td>\n",
       "      <td>112.666</td>\n",
       "      <td>112.692</td>\n",
       "      <td>112.582</td>\n",
       "      <td>112.592</td>\n",
       "      <td>749.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-02 08:00:00</td>\n",
       "      <td>112.594</td>\n",
       "      <td>112.790</td>\n",
       "      <td>112.594</td>\n",
       "      <td>112.773</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-02 09:00:00</td>\n",
       "      <td>112.775</td>\n",
       "      <td>112.793</td>\n",
       "      <td>112.722</td>\n",
       "      <td>112.736</td>\n",
       "      <td>381.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-02 10:00:00</td>\n",
       "      <td>112.738</td>\n",
       "      <td>112.752</td>\n",
       "      <td>112.659</td>\n",
       "      <td>112.723</td>\n",
       "      <td>618.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-01-02 11:00:00</td>\n",
       "      <td>112.720</td>\n",
       "      <td>112.751</td>\n",
       "      <td>112.704</td>\n",
       "      <td>112.714</td>\n",
       "      <td>319.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31 19:00:00</td>\n",
       "      <td>110.148</td>\n",
       "      <td>110.155</td>\n",
       "      <td>110.006</td>\n",
       "      <td>110.040</td>\n",
       "      <td>842.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31 20:00:00</td>\n",
       "      <td>110.038</td>\n",
       "      <td>110.065</td>\n",
       "      <td>109.883</td>\n",
       "      <td>109.943</td>\n",
       "      <td>862.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31 21:00:00</td>\n",
       "      <td>109.946</td>\n",
       "      <td>109.972</td>\n",
       "      <td>109.827</td>\n",
       "      <td>109.877</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31 22:00:00</td>\n",
       "      <td>109.880</td>\n",
       "      <td>110.056</td>\n",
       "      <td>109.850</td>\n",
       "      <td>110.024</td>\n",
       "      <td>947.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-31 23:00:00</td>\n",
       "      <td>110.026</td>\n",
       "      <td>110.034</td>\n",
       "      <td>109.942</td>\n",
       "      <td>110.017</td>\n",
       "      <td>904.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6210 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close  amount  complete\n",
       "time                                                                     \n",
       "2018-01-02 07:00:00  112.666  112.692  112.582  112.592   749.0      True\n",
       "2018-01-02 08:00:00  112.594  112.790  112.594  112.773  1220.0      True\n",
       "2018-01-02 09:00:00  112.775  112.793  112.722  112.736   381.0      True\n",
       "2018-01-02 10:00:00  112.738  112.752  112.659  112.723   618.0      True\n",
       "2018-01-02 11:00:00  112.720  112.751  112.704  112.714   319.0      True\n",
       "...                      ...      ...      ...      ...     ...       ...\n",
       "2018-12-31 19:00:00  110.148  110.155  110.006  110.040   842.0      True\n",
       "2018-12-31 20:00:00  110.038  110.065  109.883  109.943   862.0      True\n",
       "2018-12-31 21:00:00  109.946  109.972  109.827  109.877  1064.0      True\n",
       "2018-12-31 22:00:00  109.880  110.056  109.850  110.024   947.0      True\n",
       "2018-12-31 23:00:00  110.026  110.034  109.942  110.017   904.0      True\n",
       "\n",
       "[6210 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oandapyV20 import API\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "# start～endまでのデータ取得\n",
    "def get_period_data(start, end, minute, instrument):\n",
    "    timestamp = start.timestamp()\n",
    "    concats = []\n",
    "    count = 5000\n",
    "    while True:\n",
    "        df, last_timestamp = send_api(count, timestamp, minute, instrument)\n",
    "        concats.append(df)\n",
    "#         print(df)\n",
    "        if last_timestamp > end.timestamp() or len(df) < count:\n",
    "            break\n",
    "        timestamp = last_timestamp + (60 * minute)\n",
    "    df = pd.concat(concats)\n",
    "    if end is None:\n",
    "        print(df)\n",
    "        return df\n",
    "    else:\n",
    "        return df[df.index < end]\n",
    "# 時間足のdfを取得\n",
    "def send_api(count, start, minute, instrument):\n",
    "    # oandaへのリクエストの送信\n",
    "    #api_key = '取得したアクセストークンを入れてください'\n",
    "    api = API(access_token=api_key, environment=\"practice\", headers={\"Accept-Datetime-Format\":\"Unix\"})\n",
    "    if minute == 1/60:\n",
    "        granularity = 'S5'\n",
    "    elif minute == 1:\n",
    "        granularity = 'M1'\n",
    "    elif minute == 5:\n",
    "        granularity = 'M5'\n",
    "    elif minute == 15:\n",
    "        granularity = 'M15'\n",
    "    elif minute == 60:\n",
    "        granularity = 'H1'\n",
    "    params = {\n",
    "        'count': count,\n",
    "        'granularity': granularity,\n",
    "    }\n",
    "    if start is not None:\n",
    "        params['from'] = start\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument, params=params)\n",
    "    response = api.request(r)\n",
    "\n",
    "    # レスポンスの整形\n",
    "    def join_json(candle):\n",
    "        tmp = candle['mid']\n",
    "        tmp['time'] = candle['time']\n",
    "        tmp['v'] = candle['volume']\n",
    "        tmp['complete'] = candle['complete']\n",
    "        return tmp\n",
    "    data_list = [join_json(candle) for candle in response['candles']]\n",
    "    df = pd.DataFrame(data_list)\n",
    "    last_timestamp = int(float(df.iloc[-1]['time']))\n",
    "    \n",
    "    # 型変更\n",
    "    df['time'] = df['time'].astype('float64')\n",
    "    df['o'] = df['o'].astype('float64')\n",
    "    df['h'] = df['h'].astype('float64')\n",
    "    df['l'] = df['l'].astype('float64')\n",
    "    df['c'] = df['c'].astype('float64')\n",
    "    df['v'] = df['v'].astype('float64')\n",
    "\n",
    "    # タイムゾーンの変更、インデックス化\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df['time'] = df['time'] + pd.Timedelta('09:00:00') # 日本時間へ変換\n",
    "    df.set_index('time', inplace=True)                 # 時間をインデックスにする\n",
    "    df = df.loc[:,['o','h','l', 'c', 'v', 'complete']] # 列の順番変更\n",
    "    df = df.rename(columns={'o': 'open', 'h': 'high', 'l': 'low', 'c': 'close', 'v': 'amount'})\n",
    "\n",
    "    return df, last_timestamp\n",
    "minute = 60\n",
    "start = datetime.strptime('2018-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "# end = datetime.now()\n",
    "end = datetime.strptime('2019-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "instrument = 'USD_JPY'\n",
    "df = get_period_data(start, end, minute, instrument=instrument)\n",
    "df = df.reset_index().drop_duplicates(subset='time',keep='first').set_index('time')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c6b1521be4d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'complete'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Mistake in naming the variable...:( it's not supposed to be df_open\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_new = df.drop(columns=['complete']) #Mistake in naming the variable...:( it's not supposed to be df_open\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_new, test_size=0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm_in = []\n",
    "for i in range(len(train)-window_len):\n",
    "    temp = train[i:(i+window_len)].copy()\n",
    "    for col in train:\n",
    "        temp.loc[:, col] = temp[col] / temp[col].iloc[0] - 1\n",
    "    train_lstm_in.append(temp)\n",
    "lstm_train_out = (train['close'][window_len:].values / train['close'][:-window_len].values)-1\n",
    "\n",
    "test_lstm_in = []\n",
    "for i in range(len(test) - window_len):\n",
    "    temp = test[i:(i + window_len)].copy()\n",
    "    for col in test:\n",
    "        temp.loc[:, col] = temp[col] / temp[col].iloc[0] - 1\n",
    "    test_lstm_in.append(temp)\n",
    "lstm_test_out = (test['close'][window_len:].values / test['close'][:-window_len].values)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm_in = [np.array(train_lstm_input) for train_lstm_input in train_lstm_in]\n",
    "train_lstm_in = np.array(train_lstm_in)\n",
    "\n",
    "test_lstm_in = [np.array(test_lstm_input) for test_lstm_input in test_lstm_in]\n",
    "test_lstm_in = np.array(test_lstm_in)\n",
    "test_lstm_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs, output_size, neurons, activ_func=\"linear\",\n",
    "               dropout=0.25, loss=\"mae\", optimizer=\"adam\"):\n",
    "    model = Sequential()\n",
    "    \n",
    "    #(4944, 24, 5)\n",
    "    model.add(LSTM(neurons, return_sequences=True, input_shape = (inputs.shape[1], inputs.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(LSTM(neurons, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(LSTM(neurons, return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(LSTM(neurons))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "    \n",
    "#     model.add(LSTM(neurons, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(Dense(units=output_size))\n",
    "#     model.add(Activation(activ_func))\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "np.random.seed(202)\n",
    "\n",
    "yen_model = build_model(train_lstm_in, output_size=1, neurons=50)\n",
    "\n",
    "yen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yen_history = yen_model.fit(train_lstm_in, lstm_train_out, epochs=100, batch_size=32, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1)\n",
    "\n",
    "ax1.plot(yen_history.epoch, yen_history.history['loss'])\n",
    "ax1.set_title('TrainingError')\n",
    "\n",
    "if yen_model.loss == 'mae':\n",
    "    ax1.set_ylabel('Mean Absolute Error (MAE)',fontsize=12)\n",
    "else:\n",
    "    ax1.set_ylabel('Model Loss',fontsize=12)\n",
    "ax1.set_xlabel('# Epochs',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools.eval_measures import rmse\n",
    "fig, ax1 = plt.subplots(1,1,figsize=(12,8))\n",
    "ax1.plot(train.index[window_len:],\n",
    "    train['close'][window_len:], label='Actual', color='blue', )\n",
    "ax1.legend()\n",
    "ax1.plot(train.index[window_len:],\n",
    "    ((np.transpose(yen_model.predict(train_lstm_in))+1)*train['close'].values[:-window_len])[0],\n",
    "            label='Predicted', color='red')\n",
    "ax1.legend()\n",
    "ax1.set_title('Prediction for Training Data({})'.format(instrument))\n",
    "ax1.grid(True)\n",
    "\n",
    "error_train = rmse(train['close'][window_len:], ((np.transpose(yen_model.predict(train_lstm_in))+1)*train['close'].values[:-window_len])[0])\n",
    "print('STD of train data[close]: {}'.format(train['close'].std()))\n",
    "print(f'RMSE: {error_train}')\n",
    "per = round(error_train/train['close'].std()*100, 2)\n",
    "print('Percentage RMSE/STD: {}%'.format(per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1,figsize=(12,8))\n",
    "ax1.plot(test.index[window_len:],\n",
    "    test['close'][window_len:], label='Actual', color='blue')\n",
    "ax1.legend()\n",
    "ax1.plot(test.index[window_len:],\n",
    "    ((np.transpose(yen_model.predict(test_lstm_in))+1)*test['close'].values[:-window_len])[0],\n",
    "            label='Predicted', color='red')\n",
    "ax1.legend()\n",
    "ax1.set_title('Prediction for Test Data({})'.format(instrument))\n",
    "ax1.grid(True)\n",
    "\n",
    "error_test = rmse(test['close'][window_len:], ((np.transpose(yen_model.predict(test_lstm_in))+1)*test['close'].values[:-window_len])[0])\n",
    "print('STD of test data[close]: {}'.format(test['close'].std()))\n",
    "print(f'RMSE: {error_test}')\n",
    "per = round(error_test/test['close'].std()*100, 2)\n",
    "print('Percentage RMSE/STD: {}%'.format(per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['close'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.columns[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yen_model.save(\"LSTM_FX_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model(\"LSTM_FX_Model\")\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
